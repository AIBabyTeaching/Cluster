python - <<'PY'
import os, datasets, transformers, json
os.environ["HF_HOME"] = os.path.expanduser("~/.cache/hf_tiny")
datasets.load_dataset("ag_news", split="train[:2000]",
                      cache_dir=f"{os.environ['HF_HOME']}/ds")
tok = transformers.AutoTokenizer.from_pretrained(
        "google/bert_uncased_L-2_H-128_A-2",
        cache_dir=f"{os.environ['HF_HOME']}/tok")
print("Done pre-caching.")
PY


salloc --partition=torch --nodes=20 --ntasks-per-node=1 --cpus-per-task=4 --time=00:30:00

# 2) env + rendez-vous
source ~/llamaenv_local/bin/activate
cd ~/mrmito/project
export HF_HOME=$HOME/.cache/hf_tiny
export PYTHONPATH=$PWD:$PYTHONPATH
export MASTER_ADDR=$(hostname)
export MASTER_PORT=$((20000 + RANDOM % 10000))

torchrun \
  --nproc_per_node=2 \
  --rdzv_backend=c10d \
  --rdzv_endpoint=${MASTER_ADDR}:${MASTER_PORT} \
  labs/tiny/train_tiny.py \
  --subset 2000 --epochs 3
  
_________________________________________________


export HF_HOME=$HOME/.cache/hf_tiny
python labs/tiny/test_tiny.py --ckpt tiny_out